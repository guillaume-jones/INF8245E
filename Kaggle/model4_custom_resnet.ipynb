{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as reg\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "\n",
    "import kaggle_functions as kaggle\n",
    "import importlib\n",
    "importlib.reload(kaggle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, test_labels = kaggle.load_train_as_dataset()\n",
    "x_test_real = kaggle.load_test_set()\n",
    "\n",
    "batch_size = 64\n",
    "epoch_length = len(train_dataset) / batch_size\n",
    "train_dataset_augmented = kaggle.augment_dataset(train_dataset, batch_size)\n",
    "\n",
    "type_of_model = 'model4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(kt.HyperModel):\n",
    "    def residual_module(self, input, filters, stride=1, bottleneck=0, l2_reg=0.001, batch_norm=0.99):\n",
    "        # Applies bottleneck if necessary, to reduce dimensions\n",
    "        if bottleneck > 0:\n",
    "            conv_0 = layers.Conv2D(\n",
    "                bottleneck, kernel_size=(1,1),\n",
    "                padding='same', activation='relu',\n",
    "                kernel_regularizer=reg.l2(l2_reg), bias_regularizer=reg.l2(l2_reg),\n",
    "                kernel_initializer='he_normal')(input)\n",
    "        else:\n",
    "            bottleneck = filters\n",
    "            conv_0 = input\n",
    "\n",
    "        # Applies relu convolution, then linear convolution before shortcut\n",
    "        conv_1 = layers.Conv2D(\n",
    "            bottleneck, kernel_size=(3,3), strides=(stride, stride),\n",
    "            padding='same', activation='relu',\n",
    "            kernel_regularizer=reg.l2(l2_reg), bias_regularizer=reg.l2(l2_reg),\n",
    "            kernel_initializer='he_normal')(conv_0)\n",
    "        conv_2 = layers.Conv2D(\n",
    "            filters, kernel_size=(3,3), \n",
    "            padding='same', activation='linear',\n",
    "            kernel_regularizer=reg.l2(l2_reg), bias_regularizer=reg.l2(l2_reg),\n",
    "            kernel_initializer='he_normal')(conv_1)\n",
    "        \n",
    "        # Ensures shortcut is correct depth by adding a 1x1 convolution\n",
    "        if input.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(\n",
    "                filters, kernel_size=(1,1), strides=(stride,stride),\n",
    "                padding='same', activation='relu',\n",
    "                kernel_regularizer=reg.l2(l2_reg), bias_regularizer=reg.l2(l2_reg),\n",
    "                kernel_initializer='he_normal')(input)\n",
    "        else:\n",
    "            shortcut = input\n",
    "\n",
    "        # Adds shortcut\n",
    "        addition = layers.add([conv_2, shortcut])\n",
    "\n",
    "        # Batch Norm is performed in the original paper\n",
    "        if batch_norm >= 0:\n",
    "            addition = layers.BatchNormalization(momentum=batch_norm)(addition)\n",
    "\n",
    "        activation = layers.Activation('relu')(addition)\n",
    "        return activation\n",
    "\n",
    "    def conv_layer(self, input, filters, kernel, stride, l2_reg=0.001):\n",
    "        return layers.Conv2D(\n",
    "            filters, kernel_size=(kernel,kernel), strides=(stride,stride), \n",
    "            padding='same', activation='relu',\n",
    "            kernel_regularizer=reg.l2(l2_reg), bias_regularizer=reg.l2(l2_reg),\n",
    "            kernel_initializer='he_normal')(input)\n",
    "\n",
    "    def dense_layer(self, input, size, l2_reg, dropout):\n",
    "        dense = layers.Dense(\n",
    "            size, activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l2(l2_reg))(input)\n",
    "        return layers.Dropout(dropout)(dense)\n",
    "\n",
    "    def build(self, hyperparameters):\n",
    "        if hyperparameters is not None:\n",
    "            dense_l2_reg = hyperparameters.Float('dense_l2_reg', 0, 0.01, sampling='log')\n",
    "        else:\n",
    "            dense_l2_reg = 0.01\n",
    "        # Fixed hyperparameters\n",
    "        dense_dropout = 0.7\n",
    "\n",
    "        input_layer = layers.Input(shape=(96, 96, 1))\n",
    "\n",
    "        # ResNet, conv1 (input)\n",
    "        output = self.conv_layer(input_layer, 64, 7, 2)\n",
    "\n",
    "        # ResNet, conv2\n",
    "        output = self.residual_module(output, 64)\n",
    "        output = self.residual_module(output, 64)\n",
    "\n",
    "        # ResNet, conv3\n",
    "        output = self.residual_module(output, 128, 2)\n",
    "        output = self.residual_module(output, 128)\n",
    "\n",
    "        # ResNet, conv4\n",
    "        output = self.residual_module(output, 256, 2)\n",
    "        output = self.residual_module(output, 256)\n",
    "        \n",
    "        # ResNet, conv5\n",
    "        output = self.residual_module(output, 512, 2)\n",
    "        output = self.residual_module(output, 512)\n",
    "\n",
    "        # Final output\n",
    "        output = layers.GlobalAveragePooling2D()(output)\n",
    "        output = layers.Dropout(dense_dropout / 2)(output) # Not in original paper\n",
    "        output = layers.Dense(\n",
    "            128, kernel_regularizer=keras.regularizers.l2(dense_l2_reg))(output)\n",
    "        output = layers.Dropout(dense_dropout)(output) # Not in original paper\n",
    "        output = layers.Dense(\n",
    "            11, kernel_regularizer=keras.regularizers.l2(dense_l2_reg))(output)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "        # Create model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Nadam(0.0001),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "ResNet().build(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "reload_tuner = True\n",
    "tuner_filepath = 'hypertuner_2021-11-25'\n",
    "\n",
    "tuner_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "]\n",
    "\n",
    "tuner = kt.BayesianOptimization(ResNet(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=50,\n",
    "    seed=1,\n",
    "    directory=f'models/{type_of_model}',\n",
    "    project_name=tuner_filepath,\n",
    "    overwrite=(not reload_tuner))\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "if reload_tuner:\n",
    "    tuner.reload()\n",
    "else:\n",
    "    tuner.search(\n",
    "        train_dataset.batch(64).cache(), \n",
    "        validation_data=test_dataset.batch(64).cache(),\n",
    "        epochs=14, callbacks=tuner_callbacks, verbose=1)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.save(f'models/{type_of_model}/{tuner_filepath}/saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing model if wanted, otherwise create new\n",
    "use_existing_model = False\n",
    "model_name = 'resnet_1'\n",
    "if use_existing_model:\n",
    "    print(\"Loading existing model\")\n",
    "    model = keras.models.load_model(f'models/{type_of_model}/{model_name}')\n",
    "else:\n",
    "    print(\"Creating new model\")\n",
    "    model = ResNet().build(None)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "]\n",
    "\n",
    "# Fit model (can continue from loaded weights)\n",
    "history = model.fit(\n",
    "    train_dataset_augmented, \n",
    "    validation_data=test_dataset.batch(128).cache(),\n",
    "    epochs=100, steps_per_epoch=epoch_length,\n",
    "    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(model_name)\n",
    "\n",
    "kaggle.plot_model_history(history, ['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = model_name # Can be changed to evaluate older models\n",
    "model = keras.models.load_model(f'models/model4/{model_to_evaluate}')\n",
    "\n",
    "test_pred_raw = model.predict(test_dataset.batch(128))\n",
    "test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "kaggle.print_accuracy(test_labels, test_pred)\n",
    "kaggle.plot_confusion_matrix(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_pred = np.argmax(model.predict(x_test_real), axis=1)\n",
    "\n",
    "kaggle.save_test_pred(f'models/{type_of_model}/{model_name}_test_pred.csv', true_test_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
