{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open datasets\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def openPickledDataset(filename):\n",
    "    with open(filename, 'rb') as x_train_pickle:\n",
    "        return np.array(pickle.load(x_train_pickle))\n",
    "\n",
    "# Open x_train and x_test\n",
    "x_total = openPickledDataset('data/x_train.pkl') / 255.0\n",
    "x_test = openPickledDataset('data/x_test.pkl') / 255.0\n",
    "n_examples = len(x_total)\n",
    "\n",
    "# Open y_train and convert to numbers\n",
    "y_dictionary = {'big_cats':0, 'butterfly':1, 'cat':2, 'chicken':3, 'cow':4, 'dog':5, \n",
    "    'elephant':6, 'goat':7, 'horse':8, 'spider':9, 'squirrel':10}\n",
    "y_total_names = openPickledDataset('data/y_train.pkl')\n",
    "y_total = np.zeros(y_total_names.shape, dtype=int)\n",
    "for index, name in enumerate(y_total_names):\n",
    "    y_total[index] = y_dictionary[name]\n",
    "\n",
    "\n",
    "# Pour montrer les images\n",
    "# plt.imshow(x_train[0], interpolation='nearest', cmap='gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Flatten data for simple techniques\n",
    "x_total_flat = np.reshape(x_total, (x_total.shape[0], -1))\n",
    "\n",
    "# Keep holdout set for validation\n",
    "x_train_flat, x_valid_flat, y_train, y_valid = train_test_split(x_total_flat, y_total, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard functions for basic classifiers\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def showGridSearchScores(grid_search, classifier_name):\n",
    "    print(f'\\n{classifier_name} grid search:')\n",
    "    for mean, params in zip(grid_search.cv_results_['mean_test_score'], \n",
    "                            grid_search.cv_results_['params']):\n",
    "        print(f'{params} : {mean:.3f}')\n",
    "\n",
    "    print(f'Best parameters : {grid_search.best_params_}')\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def printMicroF1Score(y_pred, y_true, title):\n",
    "    f1 = f1_score(list(y_pred), list(y_true), average='micro')\n",
    "    print(title + f', F1-micro: {f1:.3f}')\n",
    "\n",
    "scoring = 'f1_micro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree, F1-micro: 0.199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.24      0.19       310\n",
      "           1       0.45      0.07      0.12       221\n",
      "           2       0.29      0.01      0.02       190\n",
      "           3       0.17      0.08      0.11       318\n",
      "           4       0.16      0.07      0.09       180\n",
      "           5       0.21      0.38      0.27       496\n",
      "           6       0.33      0.01      0.03       154\n",
      "           7       0.10      0.13      0.12       181\n",
      "           8       0.15      0.12      0.13       254\n",
      "           9       0.25      0.46      0.33       466\n",
      "          10       0.04      0.01      0.02       202\n",
      "\n",
      "    accuracy                           0.20      2972\n",
      "   macro avg       0.21      0.14      0.13      2972\n",
      "weighted avg       0.21      0.20      0.16      2972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_decision_tree = DecisionTreeClassifier(max_depth=100, ccp_alpha=0.0009)\n",
    "best_decision_tree.fit(x_train_flat, y_train)\n",
    "\n",
    "y_pred_decision_tree = best_decision_tree.predict(x_valid_flat)\n",
    "printMicroF1Score(y_pred_decision_tree, y_valid, 'Decision tree')\n",
    "print(classification_report(y_valid, y_pred_decision_tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes grid search:\n",
      "{'var_smoothing': 1e-11} : 0.205\n",
      "{'var_smoothing': 1e-10} : 0.205\n",
      "{'var_smoothing': 1e-09} : 0.205\n",
      "{'var_smoothing': 1e-08} : 0.205\n",
      "Best parameters : {'var_smoothing': 1e-11}\n",
      "Decision tree, F1-micro: 0.197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.54      0.26       310\n",
      "           1       0.14      0.05      0.07       221\n",
      "           2       0.23      0.04      0.06       190\n",
      "           3       0.24      0.04      0.07       318\n",
      "           4       0.18      0.15      0.16       180\n",
      "           5       0.24      0.05      0.08       496\n",
      "           6       0.15      0.21      0.17       154\n",
      "           7       0.13      0.36      0.19       181\n",
      "           8       0.34      0.14      0.20       254\n",
      "           9       0.29      0.40      0.34       466\n",
      "          10       0.13      0.08      0.10       202\n",
      "\n",
      "    accuracy                           0.20      2972\n",
      "   macro avg       0.20      0.19      0.16      2972\n",
      "weighted avg       0.22      0.20      0.16      2972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes grid search\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "param_grid_gnb = [\n",
    "    { 'var_smoothing': [1E-11, 1E-10, 1E-9, 1E-8] }\n",
    "]\n",
    "\n",
    "grid_search_naive_bayes = GridSearchCV(GaussianNB(), param_grid_gnb, scoring=scoring, cv=5, n_jobs=4)\n",
    "grid_search_naive_bayes.fit(x_train_flat, y_train);\n",
    "\n",
    "showGridSearchScores(grid_search_naive_bayes, \"Naive Bayes\")\n",
    "y_pred_naive_bayes = grid_search_naive_bayes.predict(x_valid_flat)\n",
    "printMicroF1Score(y_pred_naive_bayes, y_valid, 'Naive Bayes')\n",
    "print(classification_report(y_valid, y_pred_naive_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes grid search:\n",
      "{'C': 1, 'max_iter': 100, 'solver': 'saga', 'tol': 0.1} : 0.238\n",
      "{'C': 10, 'max_iter': 100, 'solver': 'saga', 'tol': 0.1} : 0.236\n",
      "{'C': 100, 'max_iter': 100, 'solver': 'saga', 'tol': 0.1} : 0.237\n",
      "{'C': 1000, 'max_iter': 100, 'solver': 'saga', 'tol': 0.1} : 0.236\n",
      "Best parameters : {'C': 1, 'max_iter': 100, 'solver': 'saga', 'tol': 0.1}\n",
      "Decision tree, F1-micro: 0.224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.22      0.21       310\n",
      "           1       0.29      0.08      0.12       221\n",
      "           2       0.06      0.01      0.01       190\n",
      "           3       0.27      0.24      0.25       318\n",
      "           4       0.17      0.08      0.11       180\n",
      "           5       0.18      0.33      0.23       496\n",
      "           6       0.09      0.02      0.03       154\n",
      "           7       0.19      0.16      0.18       181\n",
      "           8       0.28      0.26      0.27       254\n",
      "           9       0.27      0.49      0.35       466\n",
      "          10       0.16      0.02      0.04       202\n",
      "\n",
      "    accuracy                           0.22      2972\n",
      "   macro avg       0.20      0.17      0.16      2972\n",
      "weighted avg       0.21      0.22      0.20      2972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression grid search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid_log_reg = [\n",
    "    {   'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'max_iter': [100],\n",
    "        'solver' : ['saga'],\n",
    "        'tol':[0.01] }\n",
    "]\n",
    "grid_search_log_reg = GridSearchCV(LogisticRegression(), param_grid_log_reg, scoring=scoring, cv=4, n_jobs=4)\n",
    "grid_search_log_reg.fit(x_train_flat, y_train);\n",
    "\n",
    "showGridSearchScores(grid_search_log_reg, \"Logistic Regression\")\n",
    "y_pred_log_reg = grid_search_log_reg.predict(x_valid_flat)\n",
    "printMicroF1Score(y_pred_log_reg, y_valid, 'Logistic Regression')\n",
    "print(classification_report(y_valid, y_pred_log_reg))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
