{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import kaggle_functions as kaggle\n",
    "import model11_stacking\n",
    "importlib.reload(kaggle); \n",
    "importlib.reload(model11_stacking);\n",
    "from model11_stacking import Model\n",
    "\n",
    "model_number = 'model11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, valid_labels = kaggle.load_train_as_dataset()\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset_augmented, epoch_length = kaggle.augment_dataset(train_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.show_images(train_dataset_augmented, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model().build(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "298/298 [==============================] - 233s 713ms/step - loss: 5.7618 - accuracy: 0.2125 - val_loss: 3.2761 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 2/25\n",
      "298/298 [==============================] - 190s 638ms/step - loss: 4.6199 - accuracy: 0.3433 - val_loss: 2.7135 - val_accuracy: 0.7868 - lr: 1.0000e-05\n",
      "Epoch 3/25\n",
      "298/298 [==============================] - 192s 643ms/step - loss: 4.1574 - accuracy: 0.4263 - val_loss: 2.5858 - val_accuracy: 0.8335 - lr: 1.0000e-05\n",
      "Epoch 4/25\n",
      "298/298 [==============================] - 163s 545ms/step - loss: 3.8257 - accuracy: 0.5031 - val_loss: 2.5535 - val_accuracy: 0.8457 - lr: 1.0000e-05\n",
      "Epoch 5/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.5942 - accuracy: 0.5508 - val_loss: 2.5449 - val_accuracy: 0.8511 - lr: 1.0000e-05\n",
      "Epoch 6/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.5057 - accuracy: 0.5678 - val_loss: 2.5533 - val_accuracy: 0.8520 - lr: 1.0000e-05\n",
      "Epoch 7/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.3515 - accuracy: 0.6152 - val_loss: 2.5642 - val_accuracy: 0.8562 - lr: 1.0000e-05\n",
      "Epoch 8/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.3110 - accuracy: 0.6212 - val_loss: 2.5735 - val_accuracy: 0.8566 - lr: 1.0000e-05\n",
      "Epoch 9/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.1815 - accuracy: 0.6496 - val_loss: 2.5824 - val_accuracy: 0.8587 - lr: 1.0000e-05\n",
      "Epoch 10/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.1903 - accuracy: 0.6519 - val_loss: 2.5928 - val_accuracy: 0.8579 - lr: 1.0000e-05\n",
      "Epoch 11/25\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.1297 - accuracy: 0.6635\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 5e-06.\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.1297 - accuracy: 0.6635 - val_loss: 2.5991 - val_accuracy: 0.8583 - lr: 1.0000e-05\n",
      "Epoch 12/25\n",
      "298/298 [==============================] - 154s 518ms/step - loss: 3.1235 - accuracy: 0.6655 - val_loss: 2.6038 - val_accuracy: 0.8587 - lr: 5.0000e-06\n",
      "Epoch 13/25\n",
      "298/298 [==============================] - 160s 539ms/step - loss: 3.0702 - accuracy: 0.6816 - val_loss: 2.6097 - val_accuracy: 0.8579 - lr: 5.0000e-06\n",
      "Epoch 14/25\n",
      "298/298 [==============================] - 169s 567ms/step - loss: 3.0734 - accuracy: 0.6767 - val_loss: 2.6117 - val_accuracy: 0.8595 - lr: 5.0000e-06\n",
      "Epoch 15/25\n",
      "298/298 [==============================] - 170s 572ms/step - loss: 3.0398 - accuracy: 0.6883 - val_loss: 2.6163 - val_accuracy: 0.8583 - lr: 5.0000e-06\n",
      "Epoch 16/25\n",
      " 30/298 [==>...........................] - ETA: 2:04 - loss: 2.9240 - accuracy: 0.7208Training interrupted\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "# See {model}.py for specific training instructions, like epochs or valid_patience\n",
    "model_name = 'Stacking_1'\n",
    "\n",
    "model, history = kaggle.train_model(\n",
    "    Model().build(None), train_dataset_augmented, valid_dataset, \n",
    "    epochs=25, valid_patience=5, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model10/WideResNet_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(f'models/{model_number}/{model_name}')\n",
    "\n",
    "# Plot model statistics during training\n",
    "kaggle.plot_model_history(history, [['accuracy', 'val_accuracy'], ['loss', 'val_loss']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f'models/{model_number}/WideResNet_2_73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "298/298 [==============================] - 209s 672ms/step - loss: 2.2565 - accuracy: 0.9287 - val_loss: 2.6015 - val_accuracy: 0.8709\n",
      "Epoch 2/4\n",
      "298/298 [==============================] - 191s 642ms/step - loss: 2.1849 - accuracy: 0.9473 - val_loss: 2.6106 - val_accuracy: 0.8726\n",
      "Epoch 3/4\n",
      "298/298 [==============================] - 194s 652ms/step - loss: 2.1785 - accuracy: 0.9544 - val_loss: 2.6267 - val_accuracy: 0.8726\n",
      "Epoch 4/4\n",
      "298/298 [==============================] - 183s 615ms/step - loss: 2.1470 - accuracy: 0.9620 - val_loss: 2.6356 - val_accuracy: 0.8747\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "fine_model, history = kaggle.fine_tune_model(\n",
    "    model,\n",
    "    train_dataset.batch(32), valid_dataset, \n",
    "    epochs=4, epoch_length=epoch_length, learning_rate=1E-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned model\n",
    "fine_model_name = 'Stacking_1'\n",
    "fine_model.save(f'models/{model_number}/{fine_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''\n",
    "model = keras.models.load_model(f'models/{model_number}/{model_name}')\n",
    "test_pred = np.argmax(model.predict(valid_dataset.batch(128)), axis=1)\n",
    "\n",
    "kaggle.print_accuracy(valid_labels, test_pred)\n",
    "kaggle.plot_confusion_matrix(valid_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'WideResNet_3'\n",
    "kaggle.generate_test_pred_filepath(f'models/{model_number}/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stacking_0'\n",
    "kaggle.generate_test_pred(model, f'models/{model_number}/{model_name}_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kaggle.hypertune_model(\n",
    "    Model(), train_dataset.batch(32).cache(), valid_dataset, \n",
    "    model_number, 'hypertuner2021-12-03', trials=4, \n",
    "    epochs=11, valid_patience=3, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project models/model11\\hypertuner2021-12-03\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from models/model11\\hypertuner2021-12-03\\tuner0.json\n",
      "Results summary\n",
      "Results in models/model11\\hypertuner2021-12-03\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "l2_reg: 0.001\n",
      "Score: 0.8767872452735901\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "l2_reg: 0.0001\n",
      "Score: 0.8738435506820679\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "l2_reg: 0.001\n",
      "Score: 0.8717409372329712\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "l2_reg: 0.0001\n",
      "Score: 0.8708999156951904\n"
     ]
    }
   ],
   "source": [
    "tuner = kaggle.load_hypertuner(Model(), model_number, 'hypertuner2021-12-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
