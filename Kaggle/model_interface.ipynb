{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import kaggle_functions as kaggle\n",
    "import model10_wideresnet\n",
    "importlib.reload(kaggle); \n",
    "importlib.reload(model10_wideresnet);\n",
    "from model10_wideresnet import Model\n",
    "\n",
    "model_number = 'model10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, valid_labels = kaggle.load_train_as_dataset()\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset_augmented, epoch_length = kaggle.augment_dataset(train_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.show_images(train_dataset_augmented, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model().build(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "298/298 [==============================] - 240s 788ms/step - loss: 4.8863 - accuracy: 0.2031 - val_loss: 4.9331 - val_accuracy: 0.1644 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "298/298 [==============================] - 234s 786ms/step - loss: 4.0953 - accuracy: 0.2599 - val_loss: 5.7734 - val_accuracy: 0.1102 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "298/298 [==============================] - 225s 756ms/step - loss: 3.4746 - accuracy: 0.2778 - val_loss: 4.1434 - val_accuracy: 0.2931 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 3.0149 - accuracy: 0.3025 - val_loss: 4.3981 - val_accuracy: 0.1800 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.7462 - accuracy: 0.3082 - val_loss: 5.0687 - val_accuracy: 0.2140 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.5631 - accuracy: 0.3261 - val_loss: 6.4968 - val_accuracy: 0.2132 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.4477 - accuracy: 0.3284 - val_loss: 2.6996 - val_accuracy: 0.2918 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.3563 - accuracy: 0.3512 - val_loss: 2.7371 - val_accuracy: 0.2439 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.3112 - accuracy: 0.3494 - val_loss: 3.9910 - val_accuracy: 0.2792 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.2688 - accuracy: 0.3711 - val_loss: 2.7429 - val_accuracy: 0.2603 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.2595 - accuracy: 0.3674 - val_loss: 3.0454 - val_accuracy: 0.2347 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 2.2237 - accuracy: 0.3786 - val_loss: 2.4551 - val_accuracy: 0.3036 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1978 - accuracy: 0.3906 - val_loss: 2.9575 - val_accuracy: 0.2561 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1834 - accuracy: 0.4029 - val_loss: 2.1832 - val_accuracy: 0.3692 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1566 - accuracy: 0.4045 - val_loss: 2.9885 - val_accuracy: 0.2628 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1613 - accuracy: 0.4086 - val_loss: 3.3087 - val_accuracy: 0.1976 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1507 - accuracy: 0.4161 - val_loss: 2.8174 - val_accuracy: 0.3095 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1206 - accuracy: 0.4249 - val_loss: 2.8046 - val_accuracy: 0.3318 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.1067 - accuracy: 0.4301 - val_loss: 2.5558 - val_accuracy: 0.3583 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.0941 - accuracy: 0.4424 - val_loss: 2.6530 - val_accuracy: 0.3154 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.0726 - accuracy: 0.4421 - val_loss: 3.1139 - val_accuracy: 0.2893 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.0669 - accuracy: 0.4523 - val_loss: 2.5540 - val_accuracy: 0.3478 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.0491 - accuracy: 0.4536\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 2.0491 - accuracy: 0.4536 - val_loss: 2.8771 - val_accuracy: 0.3158 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.9352 - accuracy: 0.4885 - val_loss: 1.8997 - val_accuracy: 0.4899 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.8726 - accuracy: 0.4911 - val_loss: 2.8156 - val_accuracy: 0.3448 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.8293 - accuracy: 0.5038 - val_loss: 2.1167 - val_accuracy: 0.4487 - lr: 2.5000e-04\n",
      "Epoch 27/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.8299 - accuracy: 0.5019 - val_loss: 2.3191 - val_accuracy: 0.3839 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.8076 - accuracy: 0.5048 - val_loss: 2.1504 - val_accuracy: 0.4432 - lr: 2.5000e-04\n",
      "Epoch 29/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.7956 - accuracy: 0.5065 - val_loss: 2.6152 - val_accuracy: 0.3705 - lr: 2.5000e-04\n",
      "Epoch 30/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.7769 - accuracy: 0.5178 - val_loss: 1.9176 - val_accuracy: 0.4811 - lr: 2.5000e-04\n",
      "Epoch 31/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.7598 - accuracy: 0.5264 - val_loss: 1.9023 - val_accuracy: 0.4689 - lr: 2.5000e-04\n",
      "Epoch 32/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.7459 - accuracy: 0.5247 - val_loss: 3.0298 - val_accuracy: 0.3200 - lr: 2.5000e-04\n",
      "Epoch 33/200\n",
      "298/298 [==============================] - ETA: 0s - loss: 1.7349 - accuracy: 0.5283\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.7349 - accuracy: 0.5283 - val_loss: 1.9672 - val_accuracy: 0.4798 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.6525 - accuracy: 0.5592 - val_loss: 2.0213 - val_accuracy: 0.4340 - lr: 1.2500e-04\n",
      "Epoch 35/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.6127 - accuracy: 0.5690 - val_loss: 1.9628 - val_accuracy: 0.4823 - lr: 1.2500e-04\n",
      "Epoch 36/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5813 - accuracy: 0.5731 - val_loss: 1.7832 - val_accuracy: 0.5219 - lr: 1.2500e-04\n",
      "Epoch 37/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5656 - accuracy: 0.5680 - val_loss: 1.8727 - val_accuracy: 0.5046 - lr: 1.2500e-04\n",
      "Epoch 38/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5465 - accuracy: 0.5806 - val_loss: 1.9448 - val_accuracy: 0.4714 - lr: 1.2500e-04\n",
      "Epoch 39/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5317 - accuracy: 0.5877 - val_loss: 1.7445 - val_accuracy: 0.5257 - lr: 1.2500e-04\n",
      "Epoch 40/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5190 - accuracy: 0.5878 - val_loss: 1.6379 - val_accuracy: 0.5685 - lr: 1.2500e-04\n",
      "Epoch 41/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.5059 - accuracy: 0.5958 - val_loss: 1.8267 - val_accuracy: 0.5399 - lr: 1.2500e-04\n",
      "Epoch 42/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4897 - accuracy: 0.5962 - val_loss: 1.9422 - val_accuracy: 0.4807 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4874 - accuracy: 0.6015 - val_loss: 1.7015 - val_accuracy: 0.5299 - lr: 1.2500e-04\n",
      "Epoch 44/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4682 - accuracy: 0.6007 - val_loss: 2.2796 - val_accuracy: 0.4672 - lr: 1.2500e-04\n",
      "Epoch 45/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4516 - accuracy: 0.6085 - val_loss: 1.9608 - val_accuracy: 0.4865 - lr: 1.2500e-04\n",
      "Epoch 46/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4535 - accuracy: 0.6123 - val_loss: 1.6489 - val_accuracy: 0.5744 - lr: 1.2500e-04\n",
      "Epoch 47/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4423 - accuracy: 0.6170 - val_loss: 1.6410 - val_accuracy: 0.5585 - lr: 1.2500e-04\n",
      "Epoch 48/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4333 - accuracy: 0.6116 - val_loss: 1.9553 - val_accuracy: 0.5202 - lr: 1.2500e-04\n",
      "Epoch 49/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.4256 - accuracy: 0.6211 - val_loss: 1.7830 - val_accuracy: 0.5547 - lr: 1.2500e-04\n",
      "Epoch 50/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4025 - accuracy: 0.6269 - val_loss: 1.7303 - val_accuracy: 0.5576 - lr: 1.2500e-04\n",
      "Epoch 51/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4051 - accuracy: 0.6240 - val_loss: 1.7311 - val_accuracy: 0.5585 - lr: 1.2500e-04\n",
      "Epoch 52/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.4107 - accuracy: 0.6227 - val_loss: 1.8395 - val_accuracy: 0.5294 - lr: 1.2500e-04\n",
      "Epoch 53/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.3805 - accuracy: 0.6313 - val_loss: 1.7966 - val_accuracy: 0.5135 - lr: 1.2500e-04\n",
      "Epoch 54/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.3869 - accuracy: 0.6375 - val_loss: 1.7587 - val_accuracy: 0.5673 - lr: 1.2500e-04\n",
      "Epoch 55/200\n",
      "298/298 [==============================] - ETA: 0s - loss: 1.3790 - accuracy: 0.6343\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.3790 - accuracy: 0.6343 - val_loss: 1.7543 - val_accuracy: 0.5500 - lr: 1.2500e-04\n",
      "Epoch 56/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.3269 - accuracy: 0.6561 - val_loss: 1.6346 - val_accuracy: 0.5770 - lr: 6.2500e-05\n",
      "Epoch 57/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2962 - accuracy: 0.6635 - val_loss: 1.4213 - val_accuracy: 0.6266 - lr: 6.2500e-05\n",
      "Epoch 58/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2595 - accuracy: 0.6703 - val_loss: 1.4183 - val_accuracy: 0.6362 - lr: 6.2500e-05\n",
      "Epoch 59/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2586 - accuracy: 0.6684 - val_loss: 1.6613 - val_accuracy: 0.5950 - lr: 6.2500e-05\n",
      "Epoch 60/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.2504 - accuracy: 0.6783 - val_loss: 1.4536 - val_accuracy: 0.6270 - lr: 6.2500e-05\n",
      "Epoch 61/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2371 - accuracy: 0.6722 - val_loss: 1.5654 - val_accuracy: 0.5828 - lr: 6.2500e-05\n",
      "Epoch 62/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2233 - accuracy: 0.6748 - val_loss: 1.5697 - val_accuracy: 0.6030 - lr: 6.2500e-05\n",
      "Epoch 63/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.2286 - accuracy: 0.6798 - val_loss: 1.4118 - val_accuracy: 0.6430 - lr: 6.2500e-05\n",
      "Epoch 64/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.2120 - accuracy: 0.6824 - val_loss: 1.5955 - val_accuracy: 0.6072 - lr: 6.2500e-05\n",
      "Epoch 65/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1890 - accuracy: 0.6899 - val_loss: 1.6122 - val_accuracy: 0.5879 - lr: 6.2500e-05\n",
      "Epoch 66/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1787 - accuracy: 0.6971 - val_loss: 1.4954 - val_accuracy: 0.6287 - lr: 6.2500e-05\n",
      "Epoch 67/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1786 - accuracy: 0.6921 - val_loss: 1.7566 - val_accuracy: 0.5934 - lr: 6.2500e-05\n",
      "Epoch 68/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1744 - accuracy: 0.6937 - val_loss: 1.5742 - val_accuracy: 0.6026 - lr: 6.2500e-05\n",
      "Epoch 69/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1569 - accuracy: 0.6986 - val_loss: 1.3867 - val_accuracy: 0.6543 - lr: 6.2500e-05\n",
      "Epoch 70/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1493 - accuracy: 0.7019 - val_loss: 1.4820 - val_accuracy: 0.6329 - lr: 6.2500e-05\n",
      "Epoch 71/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1502 - accuracy: 0.7020 - val_loss: 1.4198 - val_accuracy: 0.6501 - lr: 6.2500e-05\n",
      "Epoch 72/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1429 - accuracy: 0.7074 - val_loss: 1.4716 - val_accuracy: 0.6333 - lr: 6.2500e-05\n",
      "Epoch 73/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1311 - accuracy: 0.7058 - val_loss: 1.3742 - val_accuracy: 0.6606 - lr: 6.2500e-05\n",
      "Epoch 74/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1264 - accuracy: 0.7116 - val_loss: 1.5927 - val_accuracy: 0.6190 - lr: 6.2500e-05\n",
      "Epoch 75/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1225 - accuracy: 0.7100 - val_loss: 1.3466 - val_accuracy: 0.6678 - lr: 6.2500e-05\n",
      "Epoch 76/200\n",
      "298/298 [==============================] - 212s 711ms/step - loss: 1.1175 - accuracy: 0.7128 - val_loss: 1.7891 - val_accuracy: 0.5770 - lr: 6.2500e-05\n",
      "Epoch 77/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.1029 - accuracy: 0.7170 - val_loss: 1.3443 - val_accuracy: 0.6720 - lr: 6.2500e-05\n",
      "Epoch 78/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.1152 - accuracy: 0.7125 - val_loss: 1.5522 - val_accuracy: 0.5997 - lr: 6.2500e-05\n",
      "Epoch 79/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.1099 - accuracy: 0.7165 - val_loss: 1.6826 - val_accuracy: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 80/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.1088 - accuracy: 0.7135 - val_loss: 1.2961 - val_accuracy: 0.6850 - lr: 6.2500e-05\n",
      "Epoch 81/200\n",
      "298/298 [==============================] - 212s 710ms/step - loss: 1.1000 - accuracy: 0.7172 - val_loss: 1.3642 - val_accuracy: 0.6674 - lr: 6.2500e-05\n",
      "Epoch 82/200\n",
      "298/298 [==============================] - 213s 714ms/step - loss: 1.0757 - accuracy: 0.7244 - val_loss: 1.3874 - val_accuracy: 0.6690 - lr: 6.2500e-05\n",
      "Epoch 83/200\n",
      "298/298 [==============================] - 226s 760ms/step - loss: 1.0711 - accuracy: 0.7275 - val_loss: 1.3354 - val_accuracy: 0.6712 - lr: 6.2500e-05\n",
      "Epoch 84/200\n",
      " 99/298 [========>.....................] - ETA: 2:35 - loss: 1.0583 - accuracy: 0.7377Training interrupted\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "# See {model}.py for specific training instructions, like epochs or valid_patience\n",
    "model_name = 'WideResNet_6'\n",
    "\n",
    "model, history = kaggle.train_model(\n",
    "    Model().build(None), train_dataset_augmented, valid_dataset, \n",
    "    epochs=120, valid_patience=16, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model10/WideResNet_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(f'models/{model_number}/{model_name}')\n",
    "\n",
    "# Plot model statistics during training\n",
    "kaggle.plot_model_history(history, [['accuracy', 'val_accuracy'], ['loss', 'val_loss']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f'models/{model_number}/WideResNet_2_73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune model\n",
    "fine_model, history = kaggle.fine_tune_model(\n",
    "    model,\n",
    "    train_dataset.batch(32), valid_dataset, \n",
    "    epochs=2, epoch_length=epoch_length, learning_rate=1E-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned model\n",
    "fine_model_name = 'WideResNet_5_84'\n",
    "fine_model.save(f'models/{model_number}/{fine_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''\n",
    "model = keras.models.load_model(f'models/{model_number}/{model_name}')\n",
    "test_pred = np.argmax(model.predict(valid_dataset.batch(128)), axis=1)\n",
    "\n",
    "kaggle.print_accuracy(valid_labels, test_pred)\n",
    "kaggle.plot_confusion_matrix(valid_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'WideResNet_3'\n",
    "kaggle.generate_test_pred_filepath(f'models/{model_number}/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stacking_0'\n",
    "kaggle.generate_test_pred(model, f'models/{model_number}/{model_name}_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kaggle.hypertune_model(\n",
    "    Model(), train_dataset.batch(32).cache(), valid_dataset, \n",
    "    model_number, 'hypertuner2021-12-03', trials=4, \n",
    "    epochs=11, valid_patience=3, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project models/model10\\hypertuner2021-12-03\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from models/model10\\hypertuner2021-12-03\\tuner0.json\n",
      "Results summary\n",
      "Results in models/model10\\hypertuner2021-12-03\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_dropout: 0.5\n",
      "k: 9\n",
      "Score: 0.8048780560493469\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_dropout: 0.3\n",
      "k: 9\n",
      "Score: 0.8015138506889343\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_dropout: 0.5\n",
      "k: 6\n",
      "Score: 0.7211942672729492\n"
     ]
    }
   ],
   "source": [
    "tuner = kaggle.load_hypertuner(Model(), model_number, 'hypertuner2021-12-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
