{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import kaggle_functions as kaggle\n",
    "import model10_wideresnet\n",
    "importlib.reload(kaggle); \n",
    "importlib.reload(model11_stacking);\n",
    "from model11_stacking import Model\n",
    "\n",
    "model_number = 'model11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, valid_labels = kaggle.load_train_as_dataset()\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset_augmented, epoch_length = kaggle.augment_dataset(train_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.show_images(train_dataset_augmented, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model().build(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "298/298 [==============================] - 141s 451ms/step - loss: 2.8242 - accuracy: 0.5981 - val_loss: 2.0878 - val_accuracy: 0.8318 - lr: 5.0000e-05\n",
      "Epoch 2/10\n",
      "298/298 [==============================] - 131s 441ms/step - loss: 1.8409 - accuracy: 0.9333 - val_loss: 2.0137 - val_accuracy: 0.8583 - lr: 5.0000e-05\n",
      "Epoch 3/10\n",
      "298/298 [==============================] - 129s 431ms/step - loss: 1.6936 - accuracy: 0.9691 - val_loss: 2.0216 - val_accuracy: 0.8688 - lr: 5.0000e-05\n",
      "Epoch 4/10\n",
      "298/298 [==============================] - 128s 431ms/step - loss: 1.6398 - accuracy: 0.9831 - val_loss: 2.0337 - val_accuracy: 0.8701 - lr: 5.0000e-05\n",
      "Epoch 5/10\n",
      "298/298 [==============================] - 129s 433ms/step - loss: 1.6192 - accuracy: 0.9843 - val_loss: 2.0507 - val_accuracy: 0.8717 - lr: 5.0000e-05\n",
      "Epoch 6/10\n",
      "298/298 [==============================] - 129s 433ms/step - loss: 1.6044 - accuracy: 0.9875 - val_loss: 2.0652 - val_accuracy: 0.8734 - lr: 5.0000e-05\n",
      "Epoch 7/10\n",
      "298/298 [==============================] - 129s 432ms/step - loss: 1.5906 - accuracy: 0.9919 - val_loss: 2.0840 - val_accuracy: 0.8738 - lr: 5.0000e-05\n",
      "Epoch 8/10\n",
      "298/298 [==============================] - 131s 441ms/step - loss: 1.5834 - accuracy: 0.9921 - val_loss: 2.0989 - val_accuracy: 0.8726 - lr: 5.0000e-05\n",
      "Epoch 9/10\n",
      "298/298 [==============================] - ETA: 0s - loss: 1.5770 - accuracy: 0.9937\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "298/298 [==============================] - 130s 436ms/step - loss: 1.5770 - accuracy: 0.9937 - val_loss: 2.1093 - val_accuracy: 0.8734 - lr: 5.0000e-05\n",
      "Epoch 10/10\n",
      "298/298 [==============================] - 130s 438ms/step - loss: 1.5739 - accuracy: 0.9938 - val_loss: 2.1141 - val_accuracy: 0.8743 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "# See {model}.py for specific training instructions, like epochs or valid_patience\n",
    "model_name = 'Stacking_0'\n",
    "\n",
    "model, history = kaggle.train_model(\n",
    "    Model().build(None), train_dataset.batch(32), valid_dataset, \n",
    "    epochs=10, valid_patience=3, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(f'models/{model_number}/{model_name}')\n",
    "\n",
    "# Plot model statistics during training\n",
    "kaggle.plot_model_history(history, [['accuracy', 'val_accuracy'], ['loss', 'val_loss']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/2\n",
      "298/298 [==============================] - 143s 458ms/step - loss: 1.7360 - accuracy: 0.9830 - val_loss: 2.3162 - val_accuracy: 0.8764\n",
      "Epoch 2/2\n",
      "298/298 [==============================] - 134s 451ms/step - loss: 1.7383 - accuracy: 0.9842 - val_loss: 2.3240 - val_accuracy: 0.8751\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "fine_model, history = kaggle.fine_tune_model(\n",
    "    model,\n",
    "    train_dataset.batch(32), valid_dataset, \n",
    "    epochs=2, epoch_length=epoch_length, learning_rate=1E-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model10/WideResNet_5_84\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\Guillaume\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# Save fine-tuned model\n",
    "fine_model_name = 'WideResNet_5_84'\n",
    "fine_model.save(f'models/{model_number}/{fine_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''\n",
    "model = keras.models.load_model(f'models/{model_number}/{model_name}')\n",
    "test_pred = np.argmax(model.predict(valid_dataset.batch(128)), axis=1)\n",
    "\n",
    "kaggle.print_accuracy(valid_labels, test_pred)\n",
    "kaggle.plot_confusion_matrix(valid_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'WideResNet_3'\n",
    "kaggle.generate_test_pred_filepath(f'models/{model_number}/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stacking_0'\n",
    "kaggle.generate_test_pred(model, f'models/{model_number}/{model_name}_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kaggle.hypertune_model(\n",
    "    Model(), train_dataset.batch(32).cache(), valid_dataset, \n",
    "    model_number, 'hypertuner2021-12-03', trials=4, \n",
    "    epochs=11, valid_patience=3, epoch_length=epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project models/model11\\hypertuner2021-12-03\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from models/model11\\hypertuner2021-12-03\\tuner0.json\n",
      "Results summary\n",
      "Results in models/model11\\hypertuner2021-12-03\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "l2_reg: 0.001\n",
      "Score: 0.8767872452735901\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "l2_reg: 0.0001\n",
      "Score: 0.8738435506820679\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "l2_reg: 0.001\n",
      "Score: 0.8717409372329712\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "l2_reg: 0.0001\n",
      "Score: 0.8708999156951904\n"
     ]
    }
   ],
   "source": [
    "tuner = kaggle.load_hypertuner(Model(), model_number, 'hypertuner2021-12-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
