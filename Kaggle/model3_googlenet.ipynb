{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "\n",
    "import kaggle_functions as kaggle\n",
    "import importlib\n",
    "importlib.reload(kaggle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, test_labels = kaggle.load_train_as_dataset()\n",
    "x_test_real = kaggle.load_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNetHyperModel(kt.HyperModel):\n",
    "    def inception_layer(self, input, f1, f3_in, f3_out, f5_in, f5_out, pool_out, dropout=0):\n",
    "        conv1 = layers.Conv2D(\n",
    "            f1, kernel_size=(1,1), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(input)\n",
    "        \n",
    "        conv3 = layers.Conv2D(\n",
    "            f3_in, (1,1), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(input)\n",
    "        conv3 = layers.Conv2D(\n",
    "            f3_out, kernel_size=(3,3), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(conv3)\n",
    "        \n",
    "        conv5 = layers.Conv2D(\n",
    "            f5_in, (1,1), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(input)\n",
    "        conv5 = layers.Conv2D(\n",
    "            f5_out, kernel_size=(5,5), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(conv5)\n",
    "        \n",
    "        pool = layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "        pool = layers.Conv2D(\n",
    "            pool_out, kernel_size=(1,1), padding='same', \n",
    "            activation='relu', kernel_initializer=keras.initializers.HeNormal())(pool)\n",
    "        \n",
    "        layer_out = layers.concatenate([conv1, conv3, conv5, pool])\n",
    "\n",
    "        if dropout == 0:\n",
    "            return layer_out\n",
    "        else:\n",
    "            return layers.Dropout(dropout)(layer_out)\n",
    "    \n",
    "    def maxpool_layer(self, input):\n",
    "        return layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(input)\n",
    "\n",
    "    def conv_layer(self, input, filter, kernel):\n",
    "        return layers.Conv2D(\n",
    "            filters=filter, kernel_size=(kernel,kernel), padding='same',\n",
    "            kernel_initializer=keras.initializers.HeNormal())(input)\n",
    "\n",
    "    def dense_layer(self, input, size, l2_reg, dropout):\n",
    "        dense = layers.Dense(\n",
    "            size, activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l2(l2_reg))(input)\n",
    "        return layers.Dropout(dropout)(dense)\n",
    "\n",
    "    def build(self, hyperparameters):\n",
    "        # Fixed hyperparameters\n",
    "        l2_reg = 0.005\n",
    "        spatial_dropout = 0.2\n",
    "        conv_dropout = 0.15\n",
    "        dense_dropout = 0.75\n",
    "        gaussian_noise = 0.05\n",
    "\n",
    "        input_layer = layers.Input(shape=(96, 96, 1))\n",
    "\n",
    "        # Input convolution\n",
    "        # Local respnorm and Spatial Dropout added\n",
    "        output = self.conv_layer(input_layer, 64, 7)\n",
    "        output = layers.SpatialDropout2D(spatial_dropout)(output)\n",
    "        output = self.maxpool_layer(output)\n",
    "        output = tf.nn.local_response_normalization(output)\n",
    "\n",
    "        # Second input convolution\n",
    "        output = self.conv_layer(output, 128, 3)\n",
    "        output = tf.nn.local_response_normalization(output)\n",
    "        output = layers.SpatialDropout2D(spatial_dropout)(output)\n",
    "        output = self.maxpool_layer(output)\n",
    "\n",
    "        # Inception layers, level 1\n",
    "        output = self.inception_layer(output, 64, 96, 128, 16, 32, 32, dropout=conv_dropout) #3a\n",
    "        output = self.inception_layer(output, 128, 128, 192, 32, 96, 64, dropout=conv_dropout) #3b\n",
    "        output = self.maxpool_layer(output)\n",
    "\n",
    "        # Inception layers, level 2\n",
    "        output = self.inception_layer(output, 192, 96, 208, 16, 48, 64, dropout=conv_dropout) #4a\n",
    "\n",
    "        # Auxilliary prediction layer\n",
    "        output = layers.AveragePooling2D(pool_size=(5,5), strides=(2,2))(output)\n",
    "        output = self.conv_layer(output, 128, 1)\n",
    "        output = layers.Flatten()(output)\n",
    "        output = self.dense_layer(output, 512, l2_reg=l2_reg, dropout=dense_dropout)\n",
    "\n",
    "        # Final output\n",
    "        output = keras.layers.Dense(11)(output)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "        # Create model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Nadam(0.0001),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "# GoogLeNetHyperModel().build(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# 12 trials at 14 max epoch took 6 hours\n",
    "\n",
    "reload_tuner = True\n",
    "tuner_filepath = 'hypertuner_2021-11-24'\n",
    "\n",
    "tuner_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "]\n",
    "\n",
    "tuner = kt.BayesianOptimization(GoogLeNetHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    seed=1,\n",
    "    directory='models/model3',\n",
    "    project_name=tuner_filepath,\n",
    "    overwrite=(not reload_tuner))\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "if reload_tuner:\n",
    "    tuner.reload()\n",
    "else:\n",
    "    tuner.search(\n",
    "        train_dataset.batch(64).cache(), \n",
    "        validation_data=test_dataset.batch(64).cache(),\n",
    "        epochs=14, callbacks=tuner_callbacks, verbose=1)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.save(f'models/model3/{tuner_filepath}/saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing model if wanted, otherwise create new\n",
    "use_existing_model = False\n",
    "model_filepath = 'models/model3/googlenet_4'\n",
    "if use_existing_model:\n",
    "    print(\"Loading existing model\")\n",
    "    model = keras.models.load_model(model_filepath)\n",
    "else:\n",
    "    print(\"Creating new model\")\n",
    "    model = GoogLeNetHyperModel().build()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "]\n",
    "\n",
    "# Fit model (can continue from loaded weights)\n",
    "history1 = model.fit(\n",
    "    train_dataset.batch(64).cache(), \n",
    "    validation_data=test_dataset.batch(64).cache(),\n",
    "    epochs=80, callbacks=callbacks, verbose=1)\n",
    "\n",
    "# Save model\n",
    "model.save(model_filepath)\n",
    "\n",
    "kaggle.plot_model_history(history1, ['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = 'googlenet_3_66'\n",
    "# model = keras.models.load_model(f'models/model3/{model_to_evaluate}')\n",
    "\n",
    "test_pred_raw = model.predict(test_dataset.batch(128))\n",
    "test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "kaggle.print_accuracy(test_labels, test_pred)\n",
    "kaggle.plot_confusion_matrix(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_pred = np.argmax(model.predict(x_test_real), axis=1)\n",
    "\n",
    "kaggle.save_test_pred(f'models/model3/{model_to_evaluate}/{model_to_evaluate}_test_pred.csv', true_test_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7beeab9d32b3e3d5812740b027dff7f9e17fcb136aeeec3859d957b5a4907666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
